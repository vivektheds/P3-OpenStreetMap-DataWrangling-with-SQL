{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import pprint\n",
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "import codecs\n",
    "import csv\n",
    "import cerberus\n",
    "import copy\n",
    "import schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from schema import Schema\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields = NODE_FIELDS, way_attr_fields = WAY_FIELDS,\n",
    "                  problem_chars = PROBLEMCHARS, default_tag_type = 'regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for node in NODE_FIELDS:\n",
    "            node_attribs[node] = element.attrib[node]\n",
    "        for child in element:\n",
    "            tag = {}\n",
    "            if PROBLEMCHARS.search(child.attrib[\"k\"]):\n",
    "                continue\n",
    "        \n",
    "            elif LOWER_COLON.search(child.attrib[\"k\"]):\n",
    "                tag_type = child.attrib[\"k\"].split(':',1)[0]\n",
    "                tag_key = child.attrib[\"k\"].split(':',1)[1]\n",
    "                tag[\"key\"] = tag_key\n",
    "                if tag_type:\n",
    "                    tag[\"type\"] = tag_type\n",
    "                else:\n",
    "                    tag[\"type\"] = 'regular'\n",
    "            \n",
    "                tag[\"id\"] = element.attrib[\"id\"]\n",
    "                tag[\"value\"] = child.attrib[\"v\"]\n",
    "            else:\n",
    "                tag[\"value\"] = child.attrib[\"v\"]\n",
    "                tag[\"key\"] = child.attrib[\"k\"]\n",
    "                tag[\"type\"] = \"regular\"\n",
    "                tag[\"id\"] = element.attrib[\"id\"]\n",
    "            if tag:\n",
    "                tags.append(tag)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        for way in WAY_FIELDS:\n",
    "            way_attribs[way] = element.attrib[way]\n",
    "        for child in element:\n",
    "            nd = {}\n",
    "            tag = {}\n",
    "            if child.tag == 'tag':\n",
    "                if PROBLEMCHARS.search(child.attrib[\"k\"]):\n",
    "                    continue\n",
    "                elif LOWER_COLON.search(child.attrib[\"k\"]):\n",
    "                    tag_type = child.attrib[\"k\"].split(':',1)[0]\n",
    "                    tag_key = child.attrib[\"k\"].split(':',1)[1]\n",
    "                    tag[\"key\"] = tag_key\n",
    "                    if tag_type:\n",
    "                        tag[\"type\"] = tag_type\n",
    "                    else:\n",
    "                        tag[\"type\"] = 'regular'\n",
    "                    tag[\"id\"] = element.attrib[\"id\"]\n",
    "                    tag[\"value\"] = child.attrib[\"v\"]\n",
    "    \n",
    "                else:\n",
    "                    tag[\"value\"] = child.attrib[\"v\"]\n",
    "                    tag[\"key\"] = child.attrib[\"k\"]\n",
    "                    tag[\"type\"] = \"regular\"\n",
    "                    tag[\"id\"] = element.attrib[\"id\"]\n",
    "                if tag:\n",
    "                    tags.append(tag)\n",
    "                    \n",
    "            elif child.tag == 'nd':\n",
    "                nd['id'] = element.attrib[\"id\"]\n",
    "                nd['node_id'] = child.attrib[\"ref\"]\n",
    "                nd['position'] = len(way_nodes)\n",
    "            \n",
    "                if nd:\n",
    "                    way_nodes.append(nd)\n",
    "            else:\n",
    "                continue\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.iteritems()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "LA_sample = \"LA_sample.osm\"\n",
    "                    \n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(LA_sample, validate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table nodes already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4e4beb7e31c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# create nodes table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CREATE TABLE nodes (id, lat, lon, user, uid, version, changeset, timestamp);\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nodes.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: table nodes already exists"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build database of the CSV files with the repective table names.\n",
    "\"\"\"\n",
    "\n",
    "import csv, sqlite3\n",
    "\n",
    "con = sqlite3.connect(\"LosAngeles.db\")\n",
    "con.text_factory = str\n",
    "cur = con.cursor()\n",
    "\n",
    "# create nodes table\n",
    "cur.execute(\"CREATE TABLE nodes (id, lat, lon, user, uid, version, changeset, timestamp);\")\n",
    "with open('nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) \n",
    "    to_db = [(i['id'], i['lat'], i['lon'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) \\\n",
    "             for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO nodes (id, lat, lon, user, uid, version, changeset, timestamp) \\\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", to_db)\n",
    "con.commit()\n",
    "\n",
    "#create nodes_tags table\n",
    "cur.execute(\"CREATE TABLE nodes_tags (id, key, value, type);\")\n",
    "with open('nodes_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) \n",
    "    to_db = [(i['id'], i['key'], i['value'], i['type']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO nodes_tags (id, key, value, type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "con.commit()\n",
    "\n",
    "#Create ways table\n",
    "cur.execute(\"CREATE TABLE ways (id, user, uid, version, changeset, timestamp);\")\n",
    "with open('ways.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) \n",
    "    to_db = [(i['id'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways (id, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?);\", to_db)\n",
    "con.commit()\n",
    "\n",
    "#Create ways_nodes table\n",
    "cur.execute(\"CREATE TABLE ways_nodes (id, node_id, position);\")\n",
    "with open('ways_nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) \n",
    "    to_db = [(i['id'], i['node_id'], i['position']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways_nodes (id, node_id, position) VALUES (?, ?, ?);\", to_db)\n",
    "con.commit()\n",
    "\n",
    "#Create ways_tags table\n",
    "cur.execute(\"CREATE TABLE ways_tags (id, key, value, type);\")\n",
    "with open('ways_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) \n",
    "    to_db = [(i['id'], i['key'], i['value'], i['type']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways_tags (id, key, value, type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
